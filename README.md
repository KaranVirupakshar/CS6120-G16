BERT based approach for Humor Detection

Age, gender and socioeconomic background are all known to influence how people interpret jokes, making humor appreciation another highly subjective topic. Due to its emphasis on numerous word senses, and more importantly cultural understanding, humor, like most figurative language, presents interesting linguistic problems to explore in our course project. We have experimented with BERT and its variants, ALBERT and RoBERTa models. We also explored training LSTM models with and without initialized weights. We have visualized metrics such as accuracy, precision, f1-score and confusion matrices to compare the performance of these models.
